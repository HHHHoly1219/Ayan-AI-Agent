# ğŸŒ AI Agent â€œAyanâ€ â€”â€” Intelligent Assistant for Chinese Teaching

This project is built on the **Coze platform**, developing and training an [**AI teaching assistantâ€”â€œAyanâ€**](https://www.coze.cn/store/agent/7478999081919103027?bot_id=true&bid=6hna5ul3g5009).  
It is designed to support teachers in international Chinese education (especially Confucius Institute volunteers and novice teachers) by addressing challenges such as insufficient teaching resources, low preparation efficiency, limited cross-cultural adaptability, and lack of classroom interaction.  

â€œAyanâ€ provides intelligent retrieval of teaching resources in pronunciation, vocabulary, grammar, and Chinese characters, while also supporting automatic lesson plan generation and classroom interaction design. It helps reduce teacher workload and improve teaching effectiveness.  

---

## ğŸ“– Background
In the context of international Chinese education, volunteer and novice teachers often face the following challenges:
- Insufficient teaching resources and low preparation efficiency  
- Limited classroom interactivity, making it difficult to engage students  
- Lack of experience in handling cross-cultural differences  
- Difficulty in providing personalized and differentiated teaching  

Traditional language knowledge repositories (covering pronunciation, vocabulary, grammar, and characters) offer basic support but lack **intelligence, interactivity, and integration**.  

Based on needs analysis and AI technology trends, this project introduces **the AI teaching assistant â€œAyanâ€**, exploring how artificial intelligence can empower international Chinese education.

---

## âœ¨ Features
- ğŸ” **Intelligent Retrieval**: Quickly access resources on pronunciation, vocabulary, grammar, and Chinese characters  
- ğŸ“ **Automatic Lesson Plan Generation**: Create personalized lesson plans based on teaching topics and student levels  
- ğŸ§¾ **Error Analysis**: Provide immediate feedback and explanations for common student errors  
- ğŸ¨ **Multimodal Support**: Integrate text, audio, images, and video to enhance classroom interactivity  
- ğŸŒ **Cross-Cultural Adaptation**: Offer teaching suggestions based on cultural differences to assist teachers in diverse classrooms  

---

## ğŸ—ï¸ System Architecture
The project is built on the **Coze development framework**, following these steps:

1. **Needs Analysis**: Based on surveys of Confucius Institute volunteer teachers in the UK  
2. **Data Preparation**: Integration of pronunciation, vocabulary, grammar, and character repositories  
3. **AI Agent Development**: Constructing a dialog and teaching support framework with Coze  
4. **Feature Implementation**: Lesson plan generation, knowledge retrieval, and multimodal interaction  
5. **Web Deployment**: Delivering an interactive online experience  

---

## ğŸ’» Interface Example
<img width="1438" height="779" alt="Screenshot" src="https://github.com/user-attachments/assets/5b3813ec-5b63-4574-a39f-2b2f103ddf2d" />

---

## ğŸ“Š User Feedback
From questionnaires and interviews, most volunteer teachers indicated:
- â€œAyanâ€ significantly **shortens preparation time**  
- The resources provided make classes more **interactive and engaging**  
- In cross-cultural teaching contexts, it offers **practical and effective suggestions**  

---

## ğŸš€ Future Plans
- Integrate more real classroom corpora to further enhance the assistantâ€™s professionalism  
- Strengthen personalization and adaptability across different language elements (pronunciation, vocabulary, grammar, characters) and skills (listening, speaking, reading, writing)  

---

## ğŸ“š Reference
This project is based on the Masterâ€™s thesis:  
Zhang Shengjie, *The Current Status of Web-Based Language Knowledge Resource Platforms and AI Practice Recommendations: An Investigative Analysis Based on UK Confucius Institute Volunteers*  

---

## ğŸ™Œ Acknowledgments
Thanks to all Confucius Institute volunteer teachers who participated in the surveys and interviews, and to the ByteDance AI team for their support.  
Special thanks to Professors **Sheng Ruo Jing**, **Peng Zeng An**, and **Lu Guang** at Fudan University for their guidance and mentorship.  
